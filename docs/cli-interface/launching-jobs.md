---
sidebar_position: 1
---

# Launching Jobs

Fair command interface is inspired by [Docker](https://www.docker.com/).
Most of the time running a Docker command in using fair command line too will work.
You can start containers, list containers on the node, inspect logs, kill them, etc.

However, Fair tool manages the entire cluster, and thus you can run multiple jobs
at once or inspect multiple nodes. There are also additional commands designed
specifically for cluster management.

## Listing Nodes in the Cluster

Before launching any jobs it is good to inspect the cluster, i.e. see summary of all
the nodes that we have. You can do it with Fair by invoking the following command:
```shell
fair cluster info
```

## Running a Container

To run a task on a container `fair docker run <image> <command...>` command is used (similar to `docker run`).
It is a shortcut to `fair docker --node any run ...` and thus by default it runs
the job on an arbitrary node. To run the job on a specific node use `fair docker -n <node_id> run ...` command.

It does the following:
1. Starts a container on the specified node.
2. Starts a process in the container.
3. Attaches to `stdin, stdout, stderr` of the process.
   The content of `stdout` and `stderr` will be continuously sent to the server 
   such that you can interactively see process output, `stdin` will be continuously
   polled and can be used to send input to the process.

For example, try the following command 
```shell
fair docker run python:slim -- python -c "print('Hello Fair Compute')"
```

This command creates a container using public `python:slim` image containing python interpreter and
starts a python task that prints `Hello Fair Compute` to the console. By default `stdin, stdout`
and `stderr` streams are attached, and thus you can see the output of the command immediately.

### Running Container in Background

If we don't want to block until task is finished, supply `-d` argument.
Also, in this case instead of printing container output to the console
Fair will print container ID. Thus, it is also convenient to use `-d`
flag when you want to memorize the container ID for some future commands.

```shell
CONTAINER_ID=`fair docker run -d alpine sleep 10`
```

### Launching Several Jobs at Once

By default, Fair is running job on an arbitrary node which is equivalent
to specifying `-n any` option to `fair docker run` command. You can specify the 
node by supplying the node id instead of the keyword `any`. You can also
run the job on all nodes at once by using `-n all` option.

For example, let's print system information of all nodes we have in the cluster:
```shell
fair docker -n all run alpine -- uname -a
```

Another useful command to run on the cluster is `printenv FAIR_NODE_ID`. When launching
a job, Fair sets `FAIR_NODE_ID` environment variable such that job knows the id of the 
node where it runs.

Let's use it to print system information of the nodes in the cluster alongside the node id:
```shell
fair docker -n all run alpine -- sh -c 'printf "$FAIR_NODE_ID:\n  "; uname -a'
```

### Launching a Container with GPU Support

The biggest value of Fair is that it allows you to leverage the powerful GPU
that you have in your computer. We need to use nvidia runtime to make use of the 
NVidia GPU. It can be specified using the `-r` flag.

Using the aforementioned trick with `FAIR_NODE_ID`, let's print a GPU that each of our
nodes has:
```shell
fair docker -n all run -r nvidia -- ubuntu sh -c 'printf "$FAIR_NODE_ID:\n  "; nvidia-smi -L'
```

### Supplying Files

Volumes are the preferred mechanism for persisting data generated by and used by Docker containers.
However, since Fair is executing the docker command on a remote machine, data needs to be copied over first.
Fair does that automatically behind the scenes, so you can use it as you would normally use Docker.

```shell
echo "Hello Volumes" > /tmp/message.txt
fair docker run --volume "/tmp/message.txt:/app/message.txt" alpine cat /app/message.txt
```

:::info

Note that Fair simply copies the files over and is not actually mounting the local
volume onto remote machine over the network.

:::


### Exposing Ports

Another commonly used feature is port mapping. For example, if you're developing
a web service you might need that. To expose port supply `-p <port>`
or `-p <host_port>:<publish_port>` argument. Here is an example of serving a minimal
web server.

```shell
# memorize id of the node
NODE_ID=`fair docker run alpine printenv FAIR_NODE_ID`
echo $NODE_ID

# run trivial web server
echo "Trivial Web Server" > /tmp/index.html
CONTAINER_ID=`fair docker run -d -p 8080:8080 \
              --volume "/tmp/index.html:/www/index.html" \
              busybox -- httpd -f -h /www -p 8080`
echo $CONTAINER_ID

# get IP of the node where server is running
NODE_IP=`./fair docker -n $NODE_ID run curlimages/curl -- curl -sS icanhazip.com`
echo $NODE_IP

# check that the server is working
curl http://$NODE_IP:8080/

# kill the server
fair docker kill $CONTAINER_ID
```

:::info

This tutorial example is trying to access the node using its public IP. If the node is not accessible from the
internet, the example won't work. Please refer to [Serving Stable Diffusion](/docs/docs/tutorials/stable-diffusion-on-hugging-face)
tutorial to see how tunneling can be used to work around this problem.

:::

## Listing Containers on the Node

To list all running containers on the node use the following command:
```shell
fair docker ps
```

This will print all container on all the nodes because by default Fair adds `-n all`
to `fair docker ps` command.

Use `-a` flag to list all containers, including the ones that have already been
stopped. Note that Fair periodically cleans up containers on the node.

## Retrieving Container Logs

To retrieve container logs use `fair docker -n <node_id> logs <container_id>`. Here is an example
of how to start a job and retrieve logs from it afterward.
```shell
CONTAINER_ID=`fair docker -n $NODE_ID run -d alpine echo "Hello World"`
fair docker -n $NODE_ID logs $CONTAINER_ID
```

You can retrieve logs even if the task has finished. However, task containers and all the associated
information is removed after a few minutes.

## Stopping the Container

To stop (kill) the container on the node use `fair docker -n <node_id> kill <container_id>`.
Here is an example of starting some long-running command and terminating it.
```shell
CONTAINER_ID=`fair -n $NODE_ID docker run -d alpine sleep 30`
fair docker -n $NODE_ID kill $CONTAINER_ID
```

## End-to-end Example

Here is a more complete example demonstrating aforementioned commands in
action. We're going to start some long-running job, inspect its output
and finally terminate it.

```shell
# check the cluster
fair cluster info

# get id of some node in the cluster
NODE_ID=`fair docker run alpine printenv FAIR_NODE_ID`

# run a task that will be printing countdown to console for two minutes, run in background
CONTAINER_ID=`fair docker -n $NODE_ID run -d python:slim --\
  python -uc "import time; [(print(f'{120-i} seconds left'), time.sleep(1)) for i in range(120)]"`

# inspect running tasks
fair docker -n $NODE_ID ps

# check logs of the task we've started
fair docker -n $NODE_ID logs $CONTAINER_ID

# stop the task
fair docker -n $NODE_ID kill $CONTAINER_ID

# ensure that no tasks are running
fair docker -n $NODE_ID ps
```
